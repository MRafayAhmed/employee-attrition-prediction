{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8340a153",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "This section imports all necessary libraries for data analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, roc_curve\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560fc0d",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the employee attrition dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "# Update the path if needed\n",
    "DATA_PATH = '../data/WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc92d32",
   "metadata": {},
   "source": [
    "# Explore Data Structure\n",
    "Display the first few rows, data types, and basic info about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Data Structure\n",
    "df.info()\n",
    "df.dtypes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861c06f",
   "metadata": {},
   "source": [
    "# Visualize Missing Values\n",
    "Use seaborn and matplotlib to visualize missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb716d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Missing Values\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd77dc",
   "metadata": {},
   "source": [
    "# Statistical Summary\n",
    "Generate descriptive statistics for numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b18a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15e735",
   "metadata": {},
   "source": [
    "# Feature Correlation Analysis\n",
    "Compute and visualize feature correlations using seaborn heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Correlation Analysis\n",
    "plt.figure(figsize=(16,10))\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147948a6",
   "metadata": {},
   "source": [
    "# Class Distribution Visualization\n",
    "Plot the distribution of the target variable (attrition) to check for imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28564395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Visualization\n",
    "sns.countplot(x='Attrition', data=df)\n",
    "plt.title('Attrition Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05842a",
   "metadata": {},
   "source": [
    "# Handle Imbalanced Data\n",
    "Apply imbalanced-learn techniques such as SMOTE to balance the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfc18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Imbalanced Data\n",
    "X = df.drop('Attrition', axis=1)\n",
    "y = df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "print('Resampled dataset shape:', X_res.shape, y_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fc662",
   "metadata": {},
   "source": [
    "# Split Data for Modeling\n",
    "Split the dataset into training and test sets using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b125ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data for Modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)\n",
    "print('Train shape:', X_train.shape, y_train.shape)\n",
    "print('Test shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994bc3a2",
   "metadata": {},
   "source": [
    "# Train Baseline Model\n",
    "Train a baseline classifier (e.g., XGBoost) on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Baseline Model\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa531eed",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance\n",
    "Evaluate the model using accuracy, precision, recall, F1-score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb465d84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Evaluate Model Performance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred = \u001b[43mmodel\u001b[49m.predict(X_test)\n\u001b[32m      3\u001b[39m y_pred_proba = model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAccuracy:\u001b[39m\u001b[33m'\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate Model Performance\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1 Score:', f1_score(y_test, y_pred))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_pred_proba))\n",
    "print(classification_report(y_test, y_pred))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label='XGBoost (AUC = {:.2f})'.format(roc_auc_score(y_test, y_pred_proba)))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06d520",
   "metadata": {},
   "source": [
    "# Explain Model Predictions with SHAP\n",
    "Use SHAP to interpret and visualize feature importance and individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bc33bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Explain Model Predictions with SHAP\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m explainer = \u001b[43mshap\u001b[49m.Explainer(model, X_train)\n\u001b[32m      3\u001b[39m shap_values = explainer(X_test)\n\u001b[32m      4\u001b[39m shap.summary_plot(shap_values, X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'shap' is not defined"
     ]
    }
   ],
   "source": [
    "# Explain Model Predictions with SHAP\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
